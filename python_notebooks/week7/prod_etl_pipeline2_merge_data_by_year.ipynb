{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357a6a0d-7be9-4036-8331-205f50d539ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Spark session...\n",
      "üîê Configuring Spark to use AWS credentials...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Initialize Spark Session with Hadoop-AWS connector\n",
    "print(\"üöÄ Initializing Spark session...\")\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ConnectToS3\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1\") \\\n",
    "    .config(\"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Configure Spark to use s3a and AWS credentials\n",
    "print(\"üîê Configuring Spark to use AWS credentials...\")\n",
    "hadoop_conf = spark._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "hadoop_conf.set(\"fs.s3a.aws.credentials.provider\", \"com.amazonaws.auth.profile.ProfileCredentialsProvider\")\n",
    "hadoop_conf.set(\"fs.s3a.endpoint\", \"s3.us-west-2.amazonaws.com\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3cc01a1-39a0-4cc6-ac76-963aed19a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter the Channel Name:  esl_dota2\n",
      "Please Enter the Chat Years (comma-separated):  2013,2014,2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2013', '2014', '2015']\n"
     ]
    }
   ],
   "source": [
    "# Input from user\n",
    "channel_name = input(\"Please Enter the Channel Name: \")\n",
    "chat_years_input = input(\"Please Enter the Chat Years (comma-separated): \")\n",
    "# Convert input to list of years\n",
    "chat_years = [year.strip() for year in chat_years_input.split(\",\") if year.strip().isdigit() and len(year.strip()) == 4]\n",
    "print(chat_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14acb275-2c92-4719-b071-9b8675d142b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vod = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", True)\\\n",
    "                .option(\"inferSchema\", True)\\\n",
    "                .load(\"/Users/hari14/Desktop/PHD/twitch_emotes_analytics_project/data/videos_on_demand_urls/esl_dota2_vods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105704bd-5e64-4e7e-aa0f-51620170a10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Processing year 2013 for channel 'esl_dota2'...\n",
      "‚ùå Failed to read data for 2013: [PATH_NOT_FOUND] Path does not exist: s3a://twitch-emotes-analytics-project/data/processed_silver/esl_dota2/2013/*.parquet.\n",
      "\n",
      "üì¶ Processing year 2014 for channel 'esl_dota2'...\n",
      "‚ùå Failed to read data for 2014: [PATH_NOT_FOUND] Path does not exist: s3a://twitch-emotes-analytics-project/data/processed_silver/esl_dota2/2014/*.parquet.\n",
      "\n",
      "üì¶ Processing year 2015 for channel 'esl_dota2'...\n",
      "‚ùå Failed to read data for 2015: [PATH_NOT_FOUND] Path does not exist: s3a://twitch-emotes-analytics-project/data/processed_silver/esl_dota2/2015/*.parquet.\n",
      "\n",
      "üèÅ All requested years processed. Data exported to S3 Gold layer.\n"
     ]
    }
   ],
   "source": [
    "# Summary storage\n",
    "summary_rows = []\n",
    "# Step 4: Loop through each year\n",
    "for chat_year in chat_years:\n",
    "    print(f\"\\nüì¶ Processing year {chat_year} for channel '{channel_name}'...\")\n",
    "\n",
    "    # Read from S3 bucket\n",
    "    parquet_files_path = f\"s3a://twitch-emotes-analytics-project/data/processed_silver/{channel_name}/{chat_year}/*.parquet\"\n",
    "    try:\n",
    "        df = spark.read.parquet(parquet_files_path)\n",
    "        df = df.join(vod.select(\"id\", \"title\"), df[\"vod_id\"] == vod[\"id\"], how=\"left\")\n",
    "        df = df.drop(\"id\")\n",
    "        df = df.withColumnRenamed(\"title\", \"match_title\")\n",
    "        record_count = df.count()\n",
    "        missing_users = df.filter((df[\"i_user_id\"].isNull()) | (df[\"i_user_name\"].isNull())).count()\n",
    "        missing_users_pct = round((missing_users/record_count)*100,2) if record_count > 0 else 0\n",
    "        summary_rows.append({\n",
    "            \"Year\" : chat_year,\n",
    "            \"Total Emote Records\" : record_count,\n",
    "            \"Records Missing User_info\" : missing_users,\n",
    "            \"Records Missing User_info Percentage\" : missing_users_pct\n",
    "        })\n",
    "        print(f\"‚úÖ Loaded {record_count:,} records from {parquet_files_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to read data for {chat_year}: {e}\")\n",
    "        summary_rows.append({\n",
    "            \"Year\" : chat_year,\n",
    "            \"Total Emote Records\" : 0,\n",
    "            \"Records Missing User_info\" : 0,\n",
    "            \"Records Missing User_info Percentage\" : 0\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Flatten array columns for CSV\n",
    "    print(\"üõ† Flattening array columns for CSV compatibility...\")\n",
    "    df_csv = df.withColumn(\"i_badge_names\", concat_ws(\",\", \"i_badge_names\")) \\\n",
    "               .withColumn(\"i_badge_titles\", concat_ws(\",\", \"i_badge_titles\")) \\\n",
    "               .withColumn(\"i_badge_versions\", concat_ws(\",\", \"i_badge_versions\"))\n",
    "\n",
    "    # Define output paths\n",
    "    output_s3_path_parquet = f\"s3a://twitch-emotes-analytics-project/data/processed_gold/{channel_name}/{chat_year}/all_data_parquet\"\n",
    "    output_s3_path_csv = f\"s3a://twitch-emotes-analytics-project/data/processed_gold/{channel_name}/{chat_year}/all_data_csv\"\n",
    "\n",
    "    # Write Parquet output\n",
    "    print(f\"üì§ Writing full Parquet dataset to: {output_s3_path_parquet}\")\n",
    "    df.write.mode(\"overwrite\").parquet(output_s3_path_parquet)\n",
    "\n",
    "    # Write CSV output\n",
    "    print(f\"üì§ Writing CSV-friendly dataset to: {output_s3_path_csv}\")\n",
    "    df_csv.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(output_s3_path_csv)\n",
    "\n",
    "    print(f\"‚úÖ Finished writing all data for {chat_year} üéâ\")\n",
    "\n",
    "print(\"\\nüèÅ All requested years processed. Data exported to S3 Gold layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c26c77-60bc-4405-b1a0-6d59079a58d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Emote summary report saved to: /Users/hari14/Desktop/PHD/twitch_emotes_analytics_project/data/processed_gold/esl_dota2_emote_pipeline2_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(summary_rows)\n",
    "excel_path = f\"/Users/hari14/Desktop/PHD/twitch_emotes_analytics_project/data/processed_gold/{channel_name}_emote_pipeline2_summary.xlsx\"\n",
    "summary_df.to_excel(excel_path, index=False)\n",
    "print(f\"\\nüìä Emote summary report saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e255ce0a-ea20-490e-8880-60d689214577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2013,2026))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c746366-670b-4a24-8e26-35cee290243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
